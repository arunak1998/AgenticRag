{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a30435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01ef9d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "os.environ['SERPAPI_KEY'] = os.getenv('SERPAPI_KEY')\n",
    "serpapi_key = os.getenv(\"SERPAPI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd7a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://medium.com/@aktooall/traditional-rag-explained-from-query-to-summary-d1beef61ba8c\",\n",
    "    \"https://medium.com/@tejpal.abhyuday/retrieval-augmented-generation-rag-from-basics-to-advanced-a2b068fd576c\"\n",
    "]\n",
    "\n",
    "# Load documents from URLs\n",
    "docs = []\n",
    "for url in urls:\n",
    "    try:\n",
    "        loader = WebBaseLoader(url)\n",
    "        page_docs = loader.load()\n",
    "        docs.extend(page_docs)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load {url}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7d0698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    "\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84886f00",
   "metadata": {},
   "source": [
    "## Splitting the doc into chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab059fc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d48f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "documents = splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015770d7",
   "metadata": {},
   "source": [
    "## Creating vectorstore and storing as chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b94ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "# Make sure your OPENAI_API_KEY is set in environment\n",
    "embedding = OpenAIEmbeddings( model=\"text-embedding-3-large\")\n",
    "\n",
    "# Create Chroma vector DB\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents, embedding)\n",
    "\n",
    "# Create retriever from it\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f360e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import add_messages\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d7d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"vector_retriever\",\n",
    "    description=\"Semantic document search from internal knowledge base\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be69eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b7a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_decision_maker(state: AgentState):\n",
    "    message = state[\"messages\"]\n",
    "    last_message=message[-1]\n",
    "    question=last_message.content\n",
    "    response=agent_with_tools.invoke(question)\n",
    "    return {\"messages\":[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class grade(BaseModel):\n",
    "    binary_score: str = Field(description=\"Answer 'yes' if documents are relevant to the question. Else say 'no'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52db0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from typing import Literal\n",
    "\n",
    "def grade_documents(state: AgentState) -> Literal[\"generator\", \"rewriter\"]:\n",
    "    print(\"ðŸ“Š Grading retrieved docs...\")\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    user_question = messages[0].content\n",
    "    retrieved_docs = messages[-1].content\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"You're a helpful agent that checks if the given documents are relevant.\\n\"\n",
    "        \"Question: {question}\\n\"\n",
    "        \"Docs: {content}\\n\"\n",
    "        \"Reply only with yes or no.\"\n",
    "    )\n",
    "\n",
    "    llm_structured = llm.with_structured_output(grade)\n",
    "    chain = prompt | llm_structured\n",
    "\n",
    "    result = chain.invoke({\"question\": user_question, \"content\": retrieved_docs})\n",
    "    score = result.binary_score.strip().lower()\n",
    "\n",
    "    if score == \"yes\":\n",
    "        print(\"âœ… Docs are relevant â†’ generator\")\n",
    "        return \"generator\"\n",
    "    else:\n",
    "        print(\"âŒ Docs not relevant â†’ rewriter\")\n",
    "        return \"rewriter\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13b3c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "def generate_output(state: AgentState) -> dict:\n",
    "    print(\"ðŸ“ Generating final answer...\")\n",
    "\n",
    "\n",
    "    rag_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    docs = messages[-1].content\n",
    "\n",
    "    chain = rag_prompt | llm\n",
    "    response = chain.invoke({\"question\": question, \"context\": docs})\n",
    "\n",
    "    return {\n",
    "        \"messages\": [response]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7815e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rewriter(state: AgentState) -> dict:\n",
    "    print(\"âœï¸ Rewriting query...\")\n",
    "\n",
    "    from langchain_core.messages import HumanMessage\n",
    "    messages = state[\"messages\"]\n",
    "    original_question = messages[0].content\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"Rewrite the user question for better web search results:\\n\\nOriginal: {question}\\n\\nRewritten:\"\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm\n",
    "    rewritten = chain.invoke({\"question\": original_question})\n",
    "\n",
    "    return {\n",
    "        \"messages\": [rewritten]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a0b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.serpapi import SerpAPIWrapper\n",
    "\n",
    "serper_search = SerpAPIWrapper(serpapi_api_key=serpapi_key)\n",
    "def web_search_node(state: AgentState) -> dict:\n",
    "    print(\"Web Search fallback via Serper\")\n",
    "    messages = state[\"messages\"]\n",
    "    latest_query = messages[-1].content\n",
    "\n",
    "    try:\n",
    "        search_result = serper_search.run(latest_query)\n",
    "    except Exception as e:\n",
    "        search_result = f\"Web search failed: {e}\"\n",
    "\n",
    "    return {\"messages\": [HumanMessage(content=search_result)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307d91e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "\n",
    "workflow.add_node(\"LLM Decision Maker\", llm_decision_maker)\n",
    "workflow.add_node(\"Vector Retriever\", retriever_node)\n",
    "workflow.add_node(\"Output Generator\", generate_output)\n",
    "workflow.add_node(\"Query Rewriter\", query_rewriter)\n",
    "workflow.add_node(\"Web Search\", web_search_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d36d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END,START\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "\n",
    "# ðŸ”¹ Entry point\n",
    "workflow.add_edge(START, \"LLM Decision Maker\")\n",
    "\n",
    "# ðŸ”¹ Decision Maker â†’ Retriever OR END (based on tools_condition)\n",
    "workflow.add_conditional_edges(\"LLM Decision Maker\", tools_condition, {\n",
    "    \"tools\": \"Vector Retriever\",\n",
    "    END: END\n",
    "})\n",
    "\n",
    "# ðŸ”¹ Retriever â†’ grade_documents â†’ Generator or Rewriter\n",
    "workflow.add_conditional_edges(\"Vector Retriever\", grade_documents, {\n",
    "    \"generator\": \"Output Generator\",\n",
    "    \"rewriter\": \"Query Rewriter\"\n",
    "})\n",
    "\n",
    "# ðŸ”¹ Generator â†’ END\n",
    "workflow.add_edge(\"Output Generator\", END)\n",
    "\n",
    "# ðŸ”¹ Rewriter â†’ Web â†’ Decision Maker\n",
    "workflow.add_edge(\"Query Rewriter\", \"Web Search\")\n",
    "workflow.add_edge(\"Web Search\", \"LLM Decision Maker\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a710a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "app=workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc76a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5af288",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"what is Agentic Rag\")]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ed6d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
